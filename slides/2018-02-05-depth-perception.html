<!DOCTYPE html>
<html>
  <head>
    <title>2018-02-05 Depth Perception</title>
    <meta charset="utf-8">
    <meta name="author" content="Rick Gilmore" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# 2018-02-05 Depth Perception
## PSY 525.001 • Vision Science • 2018 Spring
### Rick Gilmore
### 2018-02-05 12:02:54

---



---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/spUNpyF58BY?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

---

# Today's topics

--
## Discuss project proposal

--
## Depth perception

--
## Discuss Leopold &amp; Logothetis, N. K. (1996).

---
class: center, middle, inverse

## Term project

---
class: center, middle

&lt;http://psu-psychology.github.io/psy-525-vision-spring-2018/project-proposal.html&gt;

---
class: center, middle

# Perceiving surfaces orientation (spatial layout)

## Slant, tilt, distance

---
class: center, middle

&lt;img src="https://www.researchgate.net/profile/Ari_Rosenberg/publication/259201603/figure/fig2/AS:297324476682240@1447899087131/Figure-2-Slant-tilt-representation-of-planar-surface-orientation-A-The-slant-and-tilt.png" width=800px&gt;

---
class: center, middle

&lt;img src="http://cns-alumni.bu.edu/~slehar/webstuff/pcave/marr.jpg"/&gt;

&lt;img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRQCOaEsPn4zZ_ht7Nc_8teEm_cd6IiSQ5Z25_CtDkn7aagdsBF"/&gt;

## Marr's 2.5 D sketch

---
class: center, middle

&lt;img src="https://images-na.ssl-images-amazon.com/images/I/81oIIqldheL.jpg" height=500px/&gt;

---
class: center, middle, inverse

# Depth perception

---
class: center, middle

&gt;*"For those of a creationist bent, one could note that God must have loved depth cues, for He made so many of them"*

Yonas &amp; Granrud, 1985, p. 45

---
class: middle, center

## Kinetic

## Binocular

## Static (pictoral)

## Sensorimotor

---
class: center, middle

## Monocular (kinetic, static, some sensorimotor) vs. binocular cues

---
class: center, middle

## Kinetic cues to depth

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/mkhY5lANs-k?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## [Kinetic depth effect (KDE)](https://en.wikipedia.org/wiki/Kinetic_depth_effect)

---
class: center, middle

&lt;p&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Spinning_Dancer.gif#/media/File:Spinning_Dancer.gif"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/2/21/Spinning_Dancer.gif" alt="Spinning Dancer.gif"&gt;&lt;/a&gt;&lt;br&gt;By &lt;a rel="nofollow" class="external text" href="http://procreo.jp/about.html"&gt;Nobuyuki Kayahara&lt;/a&gt; - &lt;a rel="nofollow" class="external text" href="http://procreo.jp/labo/labo13.html"&gt;Procreo Flash Design Laboratory&lt;/a&gt;, &lt;a href="https://creativecommons.org/licenses/by-sa/3.0" title="Creative Commons Attribution-Share Alike 3.0"&gt;CC BY-SA 3.0&lt;/a&gt;, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=3526328"&gt;Link&lt;/a&gt;&lt;/p&gt;

This one is also bistable

---
class: middle, center

## Kinetic depth effect

3D structure perceived from temporal sequence of 2D (outline-only) views. 

Reported in Wallach, H., &amp; O’Connell, D. N. (1953). The Kinetic Depth Effect. *Journal of Experimental Psychology*, *45*(4), 205.

---
class: middle, center

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/RdwU28bghbQ?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Structure from motion

---
class: middle, center

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/bVSaWXqQh0w?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Motion parallax

---
class: middle, center

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/tEacVpOZ1xk?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;


---
class: middle, center

&lt;img src="http://www.yorku.ca/hono/parallax_demo/Fig3.jpg"/&gt;

## The geometry of motion parallax

Where is fixation? What is the direction of motion?

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/SWDXcrZtkqY?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Texture accretion &amp; deletion

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/tGJYSIBETho" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Texture accretion &amp; deletion

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/cGIpSHw7evg?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

# Optic flow

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/V4r2HXGA8jw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Optic flow and autonomous flight

---
class: center, middle

## Binocular cues to depth

---
class: center, middle

## Stereopsis

Perception of depth and 3D structure from stimulation of both eyes

---
class: center, middle

&lt;img src="https://www.researchgate.net/profile/Johannes_Burge/publication/50907225/figure/fig2/AS:394331463667730@1471027355489/Figure-14-Geometric-and-empirical-horizontal-horopters-Circles-represent-the-left-and.png"&gt;

## Horopter

a line or surface containing all those points in space whose images fall on corresponding points of the retinas of the two eyes.

---
class: center, middle

&lt;img src="http://slideplayer.com/slide/4713192/15/images/33/Crossed+and+Uncrossed+Retinal+Disparity.jpg"/&gt;

## Retinal disparity 

Retinal image positions are "disparate" or different

---
class: center, middle

## [Random-dot stereograms](https://en.wikipedia.org/wiki/Random_dot_stereogram) 

Invented by [Béla Julesz](https://en.wikipedia.org/wiki/B%C3%A9la_Julesz)

---
class: center, middle

&lt;img src="https://www.researchgate.net/profile/Matthias_Bethge/publication/221619059/figure/fig1/AS:277371451133956@1443141916054/Figure-1-Left-Example-random-dot-stereogram-RDS-Right-Illustration-of-bincular.png"/&gt;

---

```r
library(imager)
n_pts &lt;- 100
left_img &lt;- array(round(runif(n=n_pts^2),0), dim = c(n_pts, n_pts))
plot(as.cimg(left_img), axes=FALSE)
```

![](2018-02-05-depth-perception_files/figure-html/rds-1.png)&lt;!-- --&gt;

---

```r
right_img &lt;- left_img
square_pix &lt;- 20
center_square &lt;- right_img[floor(n_pts/2-square_pix/2):floor(n_pts/2+square_pix/2),floor(n_pts/2-square_pix/2):floor(n_pts/2+square_pix/2)]
plot(as.cimg(center_square), axes=FALSE)
```

![](2018-02-05-depth-perception_files/figure-html/rds_2-1.png)&lt;!-- --&gt;

&lt;!-- --- --&gt;
&lt;!-- ```{r rds_3} --&gt;
&lt;!-- shift_pix &lt;- 5 --&gt;
&lt;!-- right_img[floor(n_pts/2) - shift_pix:floor(n_pts/2) - shift_pix + square_pix, floor(n_pts/2-square_pix/2):floor(n_pts/2+square_pix/2)] &lt;- center_square --&gt;
&lt;!-- plot(as.cimg(right_img), axes=FALSE) --&gt;
&lt;!-- ``` --&gt;

---
class: center, middle

&lt;img src="https://www.eduhk.hk/has/vrdemo/rds/iloveu.gif"&gt;

## Auto-stereogram

Can't really fuse these from *projected* image. Why?

---
class: center, middle

&lt;img src="http://www.evolbiol.ru/docs/img/images/p228.gif"/&gt;

## The "correspondence" problem

How do retinal image points/edges correspond to object points/edges?

Why can it take time to "fuse" stereograms?

---
class: center, middle

&lt;img src="http://images.slideplayer.com/15/4713027/slides/slide_3.jpg"/&gt;

---
class: center, middle

## Marr-Poggio algorithm for solving

Use: surface opacity &amp; surface continuity heuristics

Iterate until a best-fitting solution is found

---
class: center, middle

&lt;img src="http://jov.arvojournals.org/data/Journals/JOV/933541/i1534-7362-13-2-16-f01.jpeg"/&gt;

## Da Vinci stereopsis

Different eyes see different portions of surfaces

---
class: center, middle

&lt;img src="http://www.swarthmore.edu/SocSci/fdurgin1/DPX/DP-fig1.gif"/&gt;

## Geometry of self-motion, object-motion, and disparity

Durgin, F. H., Proffitt, D. R., Olson, T. J., &amp; Reinke, K. S. (1995). Comparing depth from motion with depth from binocular disparity. Journal of experimental psychology. Human perception and performance, 21(3), 679–699. psycnet.apa.org. Retrieved from https://www.ncbi.nlm.nih.gov/pubmed/7790841

---
class: center, middle

## Static (pictoral) cues to depth

---
class: center, middle

## Linear Perspective

---
class: center, middle

&lt;img src="https://i1.wp.com/teresabernardart.com/wp-content/uploads/2016/01/Linear_Perspective.jpg"&gt;

---
class: center, middle

&lt;img src="http://www.cns.nyu.edu/~david/courses/perception/lecturenotes/depth/depth-slides/Slide31.jpg"&gt;

---
class: center, middle

&lt;p&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Ponzo_illusion.gif#/media/File:Ponzo_illusion.gif"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/0/02/Ponzo_illusion.gif" alt="Ponzo illusion.gif"&gt;&lt;/a&gt;&lt;br&gt;Public Domain, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=1211098"&gt;Link&lt;/a&gt;&lt;/p&gt;

## Linear perspective + elevation over horizon = [Ponzo illusion](https://en.wikipedia.org/wiki/Ponzo_illusion)

---
class: center, middle

## Relative size

---
class: center, middle

&lt;img src="http://www.cns.nyu.edu/~david/courses/perception/lecturenotes/depth/depth-slides/Slide33.jpg"/&gt;

---
class: center, middle

&lt;img src="http://www.cns.nyu.edu/~david/courses/perception/lecturenotes/depth/depth-slides/Slide33.jpg"/&gt;

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/3t5qQB-FuJg?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## [Ames room](https://en.wikipedia.org/wiki/Ames_room)

---
class: center, middle

&lt;img src="https://upload.wikimedia.org/wikipedia/commons/8/88/Ames_room.svg"/&gt;

&lt;https://en.wikipedia.org/wiki/Ames_room&gt;

---
class: center, middle

## [Aerial perspective](https://en.wikipedia.org/wiki/Aerial_perspective)
## Defocus blur

---
class: center, middle

&lt;p&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:SerraEstrela-MAR2007-5.jpg#/media/File:SerraEstrela-MAR2007-5.jpg"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/SerraEstrela-MAR2007-5.jpg/1200px-SerraEstrela-MAR2007-5.jpg" alt="SerraEstrela-MAR2007-5.jpg" height=450px&gt;&lt;/a&gt;&lt;br&gt;By &lt;a href="//commons.wikimedia.org/wiki/User:Alvesgaspar" title="User:Alvesgaspar"&gt;Joaquim Alves Gaspar&lt;/a&gt; - &lt;span class="int-own-work" lang="en"&gt;Own work&lt;/span&gt;, &lt;a href="https://creativecommons.org/licenses/by-sa/2.5" title="Creative Commons Attribution-Share Alike 2.5"&gt;CC BY-SA 2.5&lt;/a&gt;, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=1869570"&gt;Link&lt;/a&gt;&lt;/p&gt;

---
class: center, middle

&lt;img src="https://eet-330.wikispaces.com/file/view/Picture1.jpg/142684553/432x576/Picture1.jpg" height=450px&gt;

## Interposition, occultation

---
class: center, middle

## Texture gradients

---
class: center, middle

&lt;p&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Gustave_Caillebotte_-_Paris_Street;_Rainy_Day_-_Google_Art_Project.jpg#/media/File:Gustave_Caillebotte_-_Paris_Street;_Rainy_Day_-_Google_Art_Project.jpg"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Gustave_Caillebotte_-_Paris_Street%3B_Rainy_Day_-_Google_Art_Project.jpg/1200px-Gustave_Caillebotte_-_Paris_Street%3B_Rainy_Day_-_Google_Art_Project.jpg" alt="Gustave Caillebotte - Paris Street; Rainy Day - Google Art Project.jpg"&gt;&lt;/a&gt;&lt;br&gt;By &lt;a href="https://en.wikipedia.org/wiki/en:Gustave_Caillebotte" class="extiw" title="w:en:Gustave Caillebotte"&gt;Gustave Caillebotte&lt;/a&gt; - &lt;a rel="nofollow" class="external text" href="//www.google.com/culturalinstitute/asset-viewer/5wEUCOlEf-EaVQ"&gt;5wEUCOlEf-EaVQ at Google Cultural Institute&lt;/a&gt; maximum zoom level, Public Domain, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=21909139"&gt;Link&lt;/a&gt;&lt;/p&gt;

---
class: center, middle

&lt;img src="http://www.cs.ru.nl/~ths/rt2/col/h9/texture-gradient.jpg"/&gt;

---
class: center, middle

&lt;img src="http://4.bp.blogspot.com/-gj6X_o7gnus/TkpNIgneXmI/AAAAAAAACa4/svFEyr1djeM/s1600/texture_gradient.jpg"/&gt;

&lt;http://psychsciencenotes.blogspot.com/2011/08/mirrors-are-literally-windows-to.html&gt;

---
class: center, middle

## Lighting, shading, &amp; shadow cues

---
class: center, middle

&lt;img src="http://www.cns.nyu.edu/~david/courses/perception/lecturenotes/depth/depth-slides/Slide28.jpg"/&gt;

---
class: center, middle

&lt;img src="http://www.skidmore.edu/~hfoley/PercLabs/images/bumps3.gif"/&gt;

---
class: center, middle

&lt;img src="http://art.nmu.edu/groups/cognates/wiki/7cbf8/images/10a8d.jpg"/&gt;

---
class: center, middle

# Sensorimotor cues to depth

## Palmer's "ocular" cues

---
class: center, middle

&lt;img src="http://cns-alumni.bu.edu/~slehar/webstuff/pcave/vergence.jpg"/&gt;

## Vergence

Eyes (typically) *converge* on a 3D point. Angle of vergence related to 3D geometry.

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/fXd3L4izfQI?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Accommodation

---
class: middle, center

&lt;&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/IsoHFoY5q7o?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Vergence, pupil diameter change, + accommodation

---
class: middle, center

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/P3aYqxGesqs?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Vestibular system detects head rotation, translation

---
class: center, middle

## Vestibular signals speed, direction of rotation, translation

## More motion parallax with head translation than rotation

---
class: center, middle

&lt;img src="https://www.researchgate.net/profile/Azam_Khan/publication/220306688/figure/fig3/AS:276940566089744@1443039184981/Fig-3-A-graph-depicting-the-effectiveness-of-real-world-depth-cues-Adapted-from-JE.png"&gt;

## Comparing the cues

---
class: center, middle

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/mKGWAIHkmyk?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

## Integrating the cues

Welchman, A. E. (2016). The human brain in depth: how we see in 3D. *Annual Review of Vision Science*. annualreviews.org. Retrieved from http://www.annualreviews.org/doi/abs/10.1146/annurev-vision-111815-114605

---
class: center, middle

# Heuristics

## About world, illumination conditions

---
class: center, middle

&gt;*"Only in the vision scientist's laboratory or under other conditions designed specifically to deceive the visual system do we regularly fail to apprehend the actual distance to environmental surfaces."*

Palmer, 1999, p. 202

---
class: center, middle

&lt;p&gt;&lt;a href="https://commons.wikimedia.org/wiki/File:Vertical%E2%80%93horizontal_illusion.png#/media/File:Vertical%E2%80%93horizontal_illusion.png"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/3/30/Vertical%E2%80%93horizontal_illusion.png" alt="Vertical–horizontal illusion.png"&gt;&lt;/a&gt;&lt;br&gt;By &lt;a href="//commons.wikimedia.org/w/index.php?title=User:S-kay&amp;amp;action=edit&amp;amp;redlink=1" class="new" title="User:S-kay (page does not exist)"&gt;S-kay&lt;/a&gt; - &lt;span class="int-own-work" lang="en"&gt;Own work&lt;/span&gt;, Public Domain, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=8845534"&gt;Link&lt;/a&gt;&lt;/p&gt;

---
class: center, middle

&lt;img src="http://www.pnas.org/content/pnas/99/20/13184/F1.large.jpg" height=450px&gt;

## Vertical lines seem longer than horizontal ones

Vertical-horizontal illusion

---
class: center, middle

&lt;img src="http://www.pnas.org/content/pnas/99/20/13184/F2.large.jpg" height=450px&gt;

## Reflects statistics of visual experience?

---
class: center, middle

&lt;img src="http://www.pnas.org/content/pnas/99/20/13184/F3.large.jpg" height=450px&gt;

Howe, C. Q., &amp; Purves, D. (2002). Range image statistics can explain the anomalous perception of length. Proceedings of the National Academy of Sciences of the United States of America, 99(20), 13184–13188. Retrieved from http://dx.doi.org/10.1073/pnas.162474299

---
class: center, middle

&lt;img src="http://www.annualreviews.org/na101/home/literatum/publisher/ar/journals/content/psych/2008/psych.2008.59.issue-1/annurev.psych.58.110405.085632/production/images/large/ps590167.f6.jpeg" height=450px&gt;

Geisler, W. S. (2008). Visual Perception and the Statistical Properties of Natural Scenes. *Annual Review of Psychology*, *59*(1), 167–192. Retrieved April 17, 2012, from http://www.annualreviews.org/doi/abs/10.1146/annurev.psych.58.110405.085632

---
class: center, middle

&lt;img src="http://imagebank.osa.org/getImage.xqy?img=OG0kcC5mdWxsLGpvc2FhLTIwLTctMTI5Mi1nMDA3&amp;article=josaa-20-7-1292-g007" height=450px/&gt;

Potetz, B., &amp; Lee, T. S. (2003). Statistical correlations between two-dimensional images and three-dimensional structures in natural scenes. Journal of the Optical Society of America. A, Optics, image science, and vision, 20(7), 1292–1303. Retrieved from https://www.ncbi.nlm.nih.gov/pubmed/12868635

---
class: center, middle, inverse

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/A4QcyW-qTUg?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

---
class: center, middle, inverse

# Break time

---
class: center, middle, inverse

# Leopold &amp; Logothetis, N. K. (1996)

---
# Core phenomena

- Binocular rivalry
- Neural basis of binocular rivalry
- Neural basis of "conscious" visual experience

---
# Next time...

## Perceptual organization

## Size, shape, orientation, &amp; position

---
class: center, middle

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan). Rendered HTML and supporting files are pushed to GitHub where GitHub's 'pages' feature is used to host and serve the course website.
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});
(function() {var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler"); if (!r) return; s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }"; d.head.appendChild(s);})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
